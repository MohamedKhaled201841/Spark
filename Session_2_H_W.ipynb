{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session_2_H_W.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIwZsU0haNkj"
      },
      "source": [
        "## Task 1 - SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45wCuSvgajao"
      },
      "source": [
        "### Build SparkSession:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwcbnqiymCE3"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession \n",
        "spark = (SparkSession.builder.appName('SparkSQL')\n",
        "         .enableHiveSupport() # Hive support is required to CREATE Hive TABLE (AS SELECT)\n",
        "         .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.0.1\") # To read Avro format\n",
        "         .getOrCreate())\n",
        "spark = SparkSession.builder.appName('SparkSQL').enableHiveSupport().getOrCreate()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8HITwTqnJcX"
      },
      "source": [
        "### Read the json file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93iqAB7tnMYQ"
      },
      "source": [
        "path = '/content/DataFrames_sample.json'\n",
        "df=(spark.read.format('json')\n",
        "    .option('header','true')\n",
        "    .load(path)\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNx0qMfunbKX"
      },
      "source": [
        "### Display the schema:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG4CcVJenc9y",
        "outputId": "96aff6d0-aaff-43be-a9ac-4fe327d7a01c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.printSchema\n",
        "df.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
            "|   D|   H|      HDD| Id|      Model| RAM|ScreenSize|    W|Weight|Year|\n",
            "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
            "|9.48|0.61|512GB SSD|  1|MacBook Pro|16GB|       15\"|13.75|  4.02|2015|\n",
            "|7.74|0.52|256GB SSD|  2|    MacBook| 8GB|       12\"|11.04|  2.03|2016|\n",
            "|8.94|0.68|128GB SSD|  3|MacBook Air| 8GB|     13.3\"| 12.8|  2.96|2016|\n",
            "| 8.0|20.3|  1TB SSD|  4|       iMac|64GB|       27\"| 25.6|  20.8|2017|\n",
            "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43oLte9LuGzA"
      },
      "source": [
        "### Create TempView:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld7pmE6gMIRr"
      },
      "source": [
        "df.createOrReplaceTempView(\"specs\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zaj0nHTcngEF"
      },
      "source": [
        "### Get all the data when \"Model\" equal \"MacBook Pro\":\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVFYFcjtdIGW",
        "outputId": "7058cdf0-40ac-4569-8541-66dd42c1cec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT * \n",
        "          FROM specs \n",
        "          WHERE Model = 'MacBook Pro' \n",
        "          \"\"\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[D: double, H: double, HDD: string, Id: bigint, Model: string, RAM: string, ScreenSize: string, W: double, Weight: double, Year: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCLMmjRLdjbT"
      },
      "source": [
        "### Display \"RAM\"column and count \"RAM\" column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxykutRjuF0X",
        "outputId": "83580466-ad1b-41ec-bcae-d27e451ba788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT COUNT(RAM) \n",
        "             FROM specs \n",
        "          \"\"\").show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|count(RAM)|\n",
            "+----------+\n",
            "|         4|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5nlwq4t9gvK"
      },
      "source": [
        "### Get all columns when \"Year\" column equal \"2015\"  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXxjFxN19hJl",
        "outputId": "a39f38a8-2ca2-4e56-8a0b-23f8f1550f71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT * \n",
        "          FROM specs \n",
        "          WHERE Year = 2015\n",
        "          \"\"\").show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
            "|   D|   H|      HDD| Id|      Model| RAM|ScreenSize|    W|Weight|Year|\n",
            "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
            "|9.48|0.61|512GB SSD|  1|MacBook Pro|16GB|       15\"|13.75|  4.02|2015|\n",
            "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHjK2Kqfuv24"
      },
      "source": [
        "### Get all when \"Model\" start with \"M\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m30EkY_iu1Gs",
        "outputId": "5fb62057-3c80-4e8b-baa4-0711b26d1e8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT * \n",
        "          FROM specs \n",
        "          WHERE Model LIKE \"M%\"\n",
        "          \"\"\").show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
            "|   D|   H|      HDD| Id|      Model| RAM|ScreenSize|    W|Weight|Year|\n",
            "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
            "|9.48|0.61|512GB SSD|  1|MacBook Pro|16GB|       15\"|13.75|  4.02|2015|\n",
            "|7.74|0.52|256GB SSD|  2|    MacBook| 8GB|       12\"|11.04|  2.03|2016|\n",
            "|8.94|0.68|128GB SSD|  3|MacBook Air| 8GB|     13.3\"| 12.8|  2.96|2016|\n",
            "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igw9iqJQ7TdH"
      },
      "source": [
        "### Get all data when \"Model\" column equal \"MacBook Pro\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRCGSB_W9cPc",
        "outputId": "eab3a7a2-6890-47cf-fcb3-2191cc7caa26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT * \n",
        "          FROM specs \n",
        "          WHERE Model = \"MacBook Pro\"\n",
        "          \"\"\").show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
            "|   D|   H|      HDD| Id|      Model| RAM|ScreenSize|    W|Weight|Year|\n",
            "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
            "|9.48|0.61|512GB SSD|  1|MacBook Pro|16GB|       15\"|13.75|  4.02|2015|\n",
            "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZIlmJidw1Ep"
      },
      "source": [
        "### Get all data with Multiple Conditions when \"RAM\" column equal \"8GB\" and \"Model\" column is \"Macbook\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5T7roxgnBBV",
        "outputId": "6133eb94-83c2-41f1-8049-fbeff3227a9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT * \n",
        "          FROM specs \n",
        "          WHERE Model =\"MacBook\" AND RAM=\"8GB\"\n",
        "          \"\"\").show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+---------+---+-------+---+----------+-----+------+----+\n",
            "|   D|   H|      HDD| Id|  Model|RAM|ScreenSize|    W|Weight|Year|\n",
            "+----+----+---------+---+-------+---+----------+-----+------+----+\n",
            "|7.74|0.52|256GB SSD|  2|MacBook|8GB|       12\"|11.04|  2.03|2016|\n",
            "+----+----+---------+---+-------+---+----------+-----+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk8YPAWQ8HxI"
      },
      "source": [
        "### Get all data with Multiple Conditions when \"D\" greater than or equal \"8\" and \"Model\" column is \"iMac\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDHJSpQK9MuS",
        "outputId": "ff631124-4125-421b-ce02-845038aabcdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT * \n",
        "          FROM specs \n",
        "          WHERE D >= 8 AND Model =\"iMac\"\n",
        "          \"\"\").show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-------+---+-----+----+----------+----+------+----+\n",
            "|  D|   H|    HDD| Id|Model| RAM|ScreenSize|   W|Weight|Year|\n",
            "+---+----+-------+---+-----+----+----------+----+------+----+\n",
            "|8.0|20.3|1TB SSD|  4| iMac|64GB|       27\"|25.6|  20.8|2017|\n",
            "+---+----+-------+---+-----+----+----------+----+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d6364f6"
      },
      "source": [
        "## Task 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlWhDvTPfZgu"
      },
      "source": [
        "### Read \"test1\" dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7964d064",
        "outputId": "62cf05c7-5c22-4d98-c2b6-bc5bc218b0d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "path='/content/test1.csv'\n",
        "df=(spark.read.format('csv')\n",
        "    .option('header','true')\n",
        "    .load(path)\n",
        ")\n",
        "df.show()\n",
        "df.createOrReplaceTempView(\"emp\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJKjDOKHfnCt"
      },
      "source": [
        "### Display Salary of the people less than or equal to 20000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c21edffc",
        "outputId": "91b1d33b-9c16-4dcf-a636-1cef204e88c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT *  \n",
        "          FROM emp\n",
        "          WHERE Salary <= 20000 \n",
        "          \"\"\").show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvFWNFJjf0Pq"
      },
      "source": [
        "### Display Salary of the people less than or equal to 20000 and greater than or equal 15000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26f76ee1",
        "outputId": "159090d2-108a-4932-ffa9-ca347ed9a01d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT *  \n",
        "          FROM emp\n",
        "          WHERE Salary <= 20000 AND Salary>=15000\n",
        "          \"\"\").show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VAcIXkTgN9D"
      },
      "source": [
        "## Task 3 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOeqRO2KgW34"
      },
      "source": [
        "### Read \"test3\" dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d3bd081"
      },
      "source": [
        "path=\"/content/test3.csv\"\n",
        "df=(spark.read.format('csv')\n",
        "    .option('header','true')\n",
        "    .load(path)\n",
        ")\n",
        "df.createOrReplaceTempView(\"jobs\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejyUT1rngdeR"
      },
      "source": [
        "### Display dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ed791ed",
        "outputId": "d58573c3-73eb-4515-ec58-827e81e7300f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|salary|\n",
            "+---------+------------+------+\n",
            "|    Krish|Data Science| 10000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|    Sunny|    Big Data|  2000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp42YtorghXJ"
      },
      "source": [
        "### Display schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d57d24ca",
        "outputId": "a0ab9ac1-e815-4818-d226-0c3c5ba68b8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.printSchema"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.printSchema of DataFrame[Name: string, Departments: string, salary: string]>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHxWeGCCgnww"
      },
      "source": [
        "### Group by \"Name\" column and using sum function on \"salary\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f15f8197",
        "outputId": "2282c6eb-caea-4e69-f50b-617fbb5d5f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT sum(salary),Name  \n",
        "             FROM jobs\n",
        "             GROUP BY Name\n",
        "          \"\"\").show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+\n",
            "|sum(salary)|     Name|\n",
            "+-----------+---------+\n",
            "|    35000.0|Sudhanshu|\n",
            "|    12000.0|    Sunny|\n",
            "|    19000.0|    Krish|\n",
            "|     7000.0|   Mahesh|\n",
            "+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWgkaU3bhUOL"
      },
      "source": [
        "### Group by \"Name\" column and using avg function on \"salary\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc122ace",
        "outputId": "4e6be209-2c13-4fc0-8312-5794f62f55af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT avg(salary),Name  \n",
        "             FROM jobs\n",
        "             GROUP BY Name\n",
        "          \"\"\").show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+---------+\n",
            "|       avg(salary)|     Name|\n",
            "+------------------+---------+\n",
            "|11666.666666666666|Sudhanshu|\n",
            "|            6000.0|    Sunny|\n",
            "| 6333.333333333333|    Krish|\n",
            "|            3500.0|   Mahesh|\n",
            "+------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARg_-WPKhfL5"
      },
      "source": [
        "### Group by \"Departments\" column and using sum function on \"salary\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "151d2264",
        "outputId": "355cf74b-7d20-43e1-a95e-b51922cb9a5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT sum(salary), Departments  \n",
        "             FROM jobs\n",
        "             GROUP BY Departments\n",
        "          \"\"\").show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+\n",
            "|sum(salary)| Departments|\n",
            "+-----------+------------+\n",
            "|    15000.0|         IOT|\n",
            "|    15000.0|    Big Data|\n",
            "|    43000.0|Data Science|\n",
            "+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7rdLSEXhn4W"
      },
      "source": [
        "### Group by \"Departments\" column and using mean function on \"salary\" column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66fe5552",
        "outputId": "d030fb23-f698-4deb-e069-eb143b75e3bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT avg(salary) ,Departments \n",
        "             FROM jobs\n",
        "             GROUP BY Departments\n",
        "          \"\"\").show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+\n",
            "|avg(salary)| Departments|\n",
            "+-----------+------------+\n",
            "|     7500.0|         IOT|\n",
            "|     3750.0|    Big Data|\n",
            "|    10750.0|Data Science|\n",
            "+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bndivgGjhsbq"
      },
      "source": [
        "Group by \"Departments\" column and using count function on \"Departments\" column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc7bf192",
        "outputId": "1dcccdeb-cc39-41ff-f8ff-4fbe53fd42a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT count(Departments ) ,Departments \n",
        "             FROM jobs\n",
        "             GROUP BY Departments\n",
        "          \"\"\").show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------+\n",
            "|count(Departments)| Departments|\n",
            "+------------------+------------+\n",
            "|                 2|         IOT|\n",
            "|                 4|    Big Data|\n",
            "|                 4|Data Science|\n",
            "+------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfPs99wnhwGu"
      },
      "source": [
        "### Apply agg to using sum function get the total of salaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37b26cbe",
        "outputId": "9b250a36-a774-4277-8626-d7b8e9dd98f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df=spark.sql(\"\"\"SELECT sum(salary) as salary_\n",
        "             FROM jobs\n",
        "             GROUP BY Name\n",
        "          \"\"\")\n",
        "df.groupBy().sum().show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|sum(salary_)|\n",
            "+------------+\n",
            "|     73000.0|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYD0wGPRi1FO"
      },
      "source": [
        "## Task 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJLc1PY1i-Np"
      },
      "source": [
        "You've been flown to their headquarters in Ulsan, South Korea, to assist them in accurately estimating the number of crew members a ship will need.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PEoknoejL4r"
      },
      "source": [
        "They're currently building new ships for certain customers, and they'd like you to create a model and utilize it to estimate how many crew members the ships will require.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70slYH-tjR81"
      },
      "source": [
        "Metadata:\n",
        "1. Measurements of ship size \n",
        "2. capacity \n",
        "3. crew \n",
        "4. age for 158 cruise ships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZzrhGnHkRCU"
      },
      "source": [
        "It is saved in a csv file for you called \"ITI_data.csv\". our task is to develop a regression model that will assist in predicting the number of crew members required for future ships. The client also indicated that they have found that particular cruise lines will differ in acceptable crew counts, thus this is most likely an important factor to consider when conducting your investigation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9CZzWWqZnOC",
        "outputId": "d17672e4-ed0c-47fd-f1a9-e93b37cf14ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "path=\"/content/ITI_data.csv\"\n",
        "df=(spark.read.format('csv')\n",
        "    .option('header','true')\n",
        "    .load(path)\n",
        ")\n",
        "df.createOrReplaceTempView(\"ships\")\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
            "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
            "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
            "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|\n",
            "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|\n",
            "|    Ecstasy|   Carnival| 22|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Elation|   Carnival| 15|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Fantasy|   Carnival| 23|            70.367|     20.56|  8.55| 10.22|            34.23| 9.2|\n",
            "|Fascination|   Carnival| 19|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|    Freedom|   Carnival|  6|110.23899999999999|      37.0|  9.51| 14.87|            29.79|11.5|\n",
            "|      Glory|   Carnival| 10|             110.0|     29.74|  9.51| 14.87|            36.99|11.6|\n",
            "|    Holiday|   Carnival| 28|            46.052|     14.52|  7.27|  7.26|            31.72| 6.6|\n",
            "|Imagination|   Carnival| 18|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|Inspiration|   Carnival| 17|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|     Legend|   Carnival| 11|              86.0|     21.24|  9.63| 10.62|            40.49| 9.3|\n",
            "|   Liberty*|   Carnival|  8|             110.0|     29.74|  9.51| 14.87|            36.99|11.6|\n",
            "|    Miracle|   Carnival|  9|              88.5|     21.24|  9.63| 10.62|            41.67|10.3|\n",
            "|   Paradise|   Carnival| 15|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "|      Pride|   Carnival| 12|              88.5|     21.24|  9.63| 11.62|            41.67| 9.3|\n",
            "|  Sensation|   Carnival| 20|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- Ship_name: string (nullable = true)\n",
            " |-- Cruise_line: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Tonnage: string (nullable = true)\n",
            " |-- passengers: string (nullable = true)\n",
            " |-- length: string (nullable = true)\n",
            " |-- cabins: string (nullable = true)\n",
            " |-- passenger_density: string (nullable = true)\n",
            " |-- crew: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5C3kKeB4ahF",
        "outputId": "54dd1fe7-6ea9-42e9-d365-aaa2c35b913a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df =df.selectExpr(\"cast(Ship_name as string) Ship_name\",\n",
        "                  \"cast(Cruise_line as string)  Cruise_line\",\n",
        "                  \"cast(age as int) age\",\n",
        "                  \"cast(Tonnage as double)  Tonnage\",\n",
        "                  \"cast(passengers as double) passengers\",\n",
        "                  \"cast(length as double)  length\",\n",
        "                  \"cast(cabins as double) cabins\",\n",
        "                  \"cast(crew as double)  crew\",\n",
        "                  )\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Ship_name: string (nullable = true)\n",
            " |-- Cruise_line: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Tonnage: double (nullable = true)\n",
            " |-- passengers: double (nullable = true)\n",
            " |-- length: double (nullable = true)\n",
            " |-- cabins: double (nullable = true)\n",
            " |-- crew: double (nullable = true)\n",
            "\n",
            "+-----------+-----------+---+------------------+----------+------+------+----+\n",
            "|  Ship_name|Cruise_line|age|           Tonnage|passengers|length|cabins|crew|\n",
            "+-----------+-----------+---+------------------+----------+------+------+----+\n",
            "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|3.55|\n",
            "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|3.55|\n",
            "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43| 6.7|\n",
            "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|19.1|\n",
            "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|10.0|\n",
            "|    Ecstasy|   Carnival| 22|            70.367|     20.52|  8.55|  10.2| 9.2|\n",
            "|    Elation|   Carnival| 15|            70.367|     20.52|  8.55|  10.2| 9.2|\n",
            "|    Fantasy|   Carnival| 23|            70.367|     20.56|  8.55| 10.22| 9.2|\n",
            "|Fascination|   Carnival| 19|            70.367|     20.52|  8.55|  10.2| 9.2|\n",
            "|    Freedom|   Carnival|  6|110.23899999999999|      37.0|  9.51| 14.87|11.5|\n",
            "|      Glory|   Carnival| 10|             110.0|     29.74|  9.51| 14.87|11.6|\n",
            "|    Holiday|   Carnival| 28|            46.052|     14.52|  7.27|  7.26| 6.6|\n",
            "|Imagination|   Carnival| 18|            70.367|     20.52|  8.55|  10.2| 9.2|\n",
            "|Inspiration|   Carnival| 17|            70.367|     20.52|  8.55|  10.2| 9.2|\n",
            "|     Legend|   Carnival| 11|              86.0|     21.24|  9.63| 10.62| 9.3|\n",
            "|   Liberty*|   Carnival|  8|             110.0|     29.74|  9.51| 14.87|11.6|\n",
            "|    Miracle|   Carnival|  9|              88.5|     21.24|  9.63| 10.62|10.3|\n",
            "|   Paradise|   Carnival| 15|            70.367|     20.52|  8.55|  10.2| 9.2|\n",
            "|      Pride|   Carnival| 12|              88.5|     21.24|  9.63| 11.62| 9.3|\n",
            "|  Sensation|   Carnival| 20|            70.367|     20.52|  8.55|  10.2| 9.2|\n",
            "+-----------+-----------+---+------------------+----------+------+------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uezYb-Yo3P89"
      },
      "source": [
        "#Creating Training and Test Data Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwhTXkG03PPS",
        "outputId": "3b8dc320-b51b-4937-c1eb-26645f011cd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "trainDF, testDF = df.randomSplit([.8,.2],seed=42)\n",
        "print(f\"There are {trainDF.count()} rows in the training set, and {testDF.count()} in the test set\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 133 rows in the training set, and 25 in the test set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QTNLhZSlf9_"
      },
      "source": [
        "### OneHotEncoder \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZZxxxKLZnOF"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "categoricalCols = [field for (field, dataType) in trainDF.dtypes\n",
        "                   if dataType == \"string\"]\n",
        "indexOutputCols = [x + \"_Index\" for x in categoricalCols]\n",
        "oheOutputCols = [x + \"_OHE\" for x in categoricalCols]     \n",
        "stringIndexer = StringIndexer(inputCols=categoricalCols,\n",
        "                             outputCols=indexOutputCols,\n",
        "                             handleInvalid='skip')     \n",
        "oheEncoder = OneHotEncoder(inputCols=indexOutputCols,\n",
        "                          outputCols=oheOutputCols)\n",
        "numericCols = [field for (field,dataType) in trainDF.dtypes\n",
        "              if ((dataType=='int')& (field!='crew'))]\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNCxWem0l662"
      },
      "source": [
        "###Use VectorAssembler to merge all columns into one column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "pE4ohNjVZnOG"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "assemblerInputs = oheOutputCols + numericCols\n",
        "vecAssembler = VectorAssembler(inputCols=assemblerInputs,outputCol='features')\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbf56f6AmUUl"
      },
      "source": [
        "### Create a Linear Regression Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvqnqTkunkNx"
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "lr = LinearRegression(labelCol='crew',featuresCol='features')"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVdxQTcSC6Cz"
      },
      "source": [
        "### Creating a Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqM9HxkNIHwE",
        "outputId": "17610685-99d4-4ac7-b439-6ce7b8224d53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline =Pipeline(stages = [stringIndexer,oheEncoder,vecAssembler,lr])\n",
        "pipelineModel = pipeline.fit(trainDF)\n",
        "predDF = pipelineModel.transform(testDF)\n",
        "predDF.select('features','crew','prediction').show(5)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+--------------------+\n",
            "|            features|crew|          prediction|\n",
            "+--------------------+----+--------------------+\n",
            "|(136,[26,119,135]...|12.0|    9.96842693031499|\n",
            "|(136,[49,118,135]...|8.69|  11.468189948677498|\n",
            "|(136,[89,121,135]...| 6.3|   4.014761828402714|\n",
            "|(136,[9,134,135],...|0.88|-0.35427650289577883|\n",
            "|(136,[112,133,135...|1.97|  2.5391250393848885|\n",
            "+--------------------+----+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEbfwhqeHOCc"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97G5-065-8Ko"
      },
      "source": [
        "# Using RMSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeqbUVUxILVe",
        "outputId": "601c352f-a74a-4a15-abf5-07d1d5283a38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "regressionEvaluator = RegressionEvaluator(predictionCol='prediction',\n",
        "                                         labelCol='crew',\n",
        "                                         metricName='rmse')\n",
        "rmse = regressionEvaluator.evaluate(predDF)\n",
        "#print(\"RMSE is {:.1f}\".format(rmse))\n",
        "print(f\"RMSE is {rmse:.1f}\")"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE is 1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQJXzFI4-4-0"
      },
      "source": [
        "# Using R^2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDEN8r4l-20H",
        "outputId": "625fe851-2de2-40d1-d060-e5d33003d1b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "r2 = RegressionEvaluator(predictionCol='prediction',\n",
        "                                         labelCol='crew',\n",
        "                                         metricName='r2').evaluate(predDF)\n",
        "print(f\"R2 is {r2}\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 is 0.7794811826138549\n"
          ]
        }
      ]
    }
  ]
}