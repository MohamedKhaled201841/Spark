{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical_work.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MrBC530gmg5"
      },
      "source": [
        "Let's start with your project: \n",
        "\n",
        "Are you a data scientist? \n",
        "\n",
        "I think you are an awesome  data scientist.\n",
        "\n",
        "### **Problem** \n",
        "**Our goal is to create a predictive model that can answer the following question:**\n",
        "\n",
        "**What kind of people had a better chance of surviving?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhBfwzBgioTD"
      },
      "source": [
        "**Data about passengers:**\n",
        "*   Name\n",
        "*   Age\n",
        "*   Gender.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIEH8iZqi-sk"
      },
      "source": [
        "## Install and Import Libraries\n",
        "Let's install PySpark:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj1HhvIOY5Yz"
      },
      "source": [
        "# pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDp80mG9jmfU"
      },
      "source": [
        "## Build Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttzML9fpjE5a"
      },
      "source": [
        "# importing libraries\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Lab01').getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiqECDzLj1Mg"
      },
      "source": [
        "## Data Loading\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn-hxNggkTqV"
      },
      "source": [
        "You have two datasets: \n",
        "* Train  \n",
        "* Test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8-A8M7QmKDJ"
      },
      "source": [
        "Read two datasets: \n",
        "* Train\n",
        "* Test.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0Uc2KOlEvuH"
      },
      "source": [
        "##Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx2qAccBk15y"
      },
      "source": [
        "path='/content/train.csv'\n",
        "df_train=spark.read.csv(path, header=\"true\", inferSchema=\"true\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XY6LAqNEz0S"
      },
      "source": [
        "##Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqhnN_ObE18G"
      },
      "source": [
        "path='/content/test (1).csv'\n",
        "df_test=spark.read.csv(path, header=\"true\", inferSchema=\"true\")\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj2ANTnWmSCq"
      },
      "source": [
        "Let's work with train dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5mWJR30lNs5"
      },
      "source": [
        "**Confirm if this is a dataframe or not:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEYTePrzk9yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e464785-d219-4d0f-9598-16f76b27e4e2"
      },
      "source": [
        "print(\"df_train is {}\".format(type(df_train)))\n",
        "print(\"df_test  is {}\".format(type(df_test)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_train is <class 'pyspark.sql.dataframe.DataFrame'>\n",
            "df_test  is <class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvLJElPrlT4i"
      },
      "source": [
        "**Show 5 rows.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYwhqvV8lnO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69127c3-5dcd-45b9-fc8a-72263e156025"
      },
      "source": [
        "df_train.show(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QIYVxRXlnnw"
      },
      "source": [
        "**Display schema for the dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcvERiICl1Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be572503-296a-4996-f86d-7bb5ab64d907"
      },
      "source": [
        "df_train.printSchema()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmE3Wd80l1S6"
      },
      "source": [
        "**Statistical summary:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNY0SItol5Mo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1066ce-13aa-4161-da7f-c01b0cdb0f10"
      },
      "source": [
        "df_train.summary().show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
            "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
            "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
            "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
            "|    25%|              223|                  0|                 2|                null|  null|              20.0|                 0|                  0|           19996.0|           7.8958| null|    null|\n",
            "|    50%|              446|                  0|                 3|                null|  null|              28.0|                 0|                  0|          236171.0|          14.4542| null|    null|\n",
            "|    75%|              669|                  1|                 3|                null|  null|              38.0|                 1|                  0|          347743.0|             31.0| null|    null|\n",
            "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiFaIEQTl70_"
      },
      "source": [
        "## EDA - Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSNPOnP8mw2Q"
      },
      "source": [
        "**Display count for the train dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrtpG11Fl9HM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7867597-e043-4b73-8a6b-c55903c51954"
      },
      "source": [
        "print(\"count of train dataset is {}\".format(df_train.count()))\n",
        "print(\"count of test  dataset is {}\".format(df_test.count()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count of train dataset is 891\n",
            "count of test  dataset is 438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_6nnTfxm9_x"
      },
      "source": [
        "**Can you answer this question:** \n",
        "\n",
        "**How many people survived, and how many didn't survive?** \n",
        "\n",
        "**Please save data in a variable.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDoqPwyomYxA"
      },
      "source": [
        "life=df_train.groupBy(\"Survived\").count()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8DUtZXPn46m"
      },
      "source": [
        "**Display your result:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XHAK8ceoCMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26bd4c58-ba09-4a9e-b011-b7f7c3aae55a"
      },
      "source": [
        "life.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|Survived|count|\n",
            "+--------+-----+\n",
            "|       1|  342|\n",
            "|       0|  549|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygsg7wQqor9a"
      },
      "source": [
        "**Can you display your answer in ratio form?(Hint: Use \"UDF\" Function. (Hint: Use \"UDF\" Function. This is a hint you can use any method.)**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uiaN29PoQnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e25db4f-a1c2-442d-a1ba-7d6d6f6a7596"
      },
      "source": [
        "# import org.apache.spark.sql.functions.udf package\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "countUDF = udf(lambda z: z/891)\n",
        "life.select(countUDF(F.col(\"count\")).alias(\"ratio\")).show(truncate=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|ratio             |\n",
            "+------------------+\n",
            "|0.3838383838383838|\n",
            "|0.6161616161616161|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7Aker_lp1h4"
      },
      "source": [
        "**Can you get the number of males and females?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XllkDlo3ongJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8608a36-3a1e-4f46-8911-06c82706c0ee"
      },
      "source": [
        "df_train.groupBy(\"Sex\").count().show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|   Sex|count|\n",
            "+------+-----+\n",
            "|female|  314|\n",
            "|  male|  577|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHFaJ15zqtEV"
      },
      "source": [
        "**1. What is the average number of survivors of each gender?**\n",
        "\n",
        "**2. What is the number of survivors of each gender?**\n",
        "\n",
        "(Hint: Group by the \"sex\" column. This is a hint you can use any method.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUikH7MUqdKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5206f622-4ac1-4aec-e181-3ddcc4f79202"
      },
      "source": [
        "df_train.createOrReplaceTempView(\"train_data\")\n",
        "spark.sql(\"\"\"SELECT count(*) as count ,Sex ,Survived\n",
        "                FROM train_data\n",
        "                GROUP BY Sex,Survived\n",
        "          \"\"\").show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+--------+\n",
            "|count|   Sex|Survived|\n",
            "+-----+------+--------+\n",
            "|  468|  male|       0|\n",
            "|  233|female|       1|\n",
            "|   81|female|       0|\n",
            "|  109|  male|       1|\n",
            "+-----+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCEdYNdArtRN"
      },
      "source": [
        "**Create temporary view PySpark:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjlK6HDUqsI5"
      },
      "source": [
        "df_train.createOrReplaceTempView(\"train_data\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXNePifnshHr"
      },
      "source": [
        "**How many people survived, and how many didn't survive? By SQL:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HxfPRTMslqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba2d26a-4e3a-432c-92da-979c13cc2289"
      },
      "source": [
        "spark.sql(\"\"\"SELECT count(Survived),Survived as Survived\n",
        "                FROM train_data\n",
        "                GROUP BY Survived\n",
        "          \"\"\").show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------+\n",
            "|count(Survived)|Survived|\n",
            "+---------------+--------+\n",
            "|            342|       1|\n",
            "|            549|       0|\n",
            "+---------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVCdY6EasFWV"
      },
      "source": [
        "**Can you display the number of survivors from each gender as a ratio?**\n",
        "\n",
        "(Hint: Group by \"sex\" column. This is a hint you can use any method.)\n",
        "\n",
        "**Can you do this via SQL?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xQc3pUUr3HF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0c2ec6-a9f4-43f6-b1fd-1ca957aa6b60"
      },
      "source": [
        "spark.sql(\"\"\"SELECT count(Sex),Sex as count\n",
        "                FROM train_data\n",
        "                GROUP BY Sex\n",
        "          \"\"\").show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+\n",
            "|count(Sex)| count|\n",
            "+----------+------+\n",
            "|       314|female|\n",
            "|       577|  male|\n",
            "+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6QXc5V8uu3Y"
      },
      "source": [
        "**Display a ratio for \"p-class\": SUM(Survived)/count for p-class**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mscs2mDFdFsD"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX0klxwAvg6J"
      },
      "source": [
        "**Let's take a break and continue after this.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ctM9t8atxJl"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CfanZTCt6Wk"
      },
      "source": [
        "**First and foremost, we must merge both the train and test datasets. (Hint: The union function can do this.)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nm8S1K0r4uY"
      },
      "source": [
        "unionDF = df_train.union(df_test)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI7AD8FLz3iO"
      },
      "source": [
        "**Display count:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_WERAL8wvJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963a40a7-5894-480e-f728-19db0965f715"
      },
      "source": [
        "unionDF.count()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1329"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R4Miuy0z_uP"
      },
      "source": [
        "**Can you define the number of null values in each column?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LMOalKBxhpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0672b1c-806a-42bd-91ac-4abe9b176d95"
      },
      "source": [
        "from pyspark.sql.functions import  when, count, col,isnull\n",
        "unionDF.select([count(when(isnull(c), c)).alias(c) for c in unionDF.columns]).show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|          0|       0|     0|   0|  0|265|    0|    0|     0|   0| 1021|       3|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBX8cJ000aqe"
      },
      "source": [
        "**Create Dataframe for null values**\n",
        "\n",
        "1. Column\n",
        "2. Number of missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITmyUelNxjJM"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuKrOi5a0-Ma"
      },
      "source": [
        "## Preprocessing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVQlr9vDy7Y4"
      },
      "source": [
        "**Create Temporary view PySpark:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs3yeXhGI8rv"
      },
      "source": [
        "unionDF.createOrReplaceTempView(\"union_data\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txa8NZIO1JaP"
      },
      "source": [
        "**Can you show the \"name\" column from your temporary table?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7yXqJoJy35k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e150119-4403-45b7-f18e-268d49aae0db"
      },
      "source": [
        "spark.sql(\"\"\"SELECT name\n",
        "             FROM union_data\n",
        "             \n",
        "          \"\"\").show(truncate=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------+\n",
            "|name                                                   |\n",
            "+-------------------------------------------------------+\n",
            "|Braund, Mr. Owen Harris                                |\n",
            "|Cumings, Mrs. John Bradley (Florence Briggs Thayer)    |\n",
            "|Heikkinen, Miss. Laina                                 |\n",
            "|Futrelle, Mrs. Jacques Heath (Lily May Peel)           |\n",
            "|Allen, Mr. William Henry                               |\n",
            "|Moran, Mr. James                                       |\n",
            "|McCarthy, Mr. Timothy J                                |\n",
            "|Palsson, Master. Gosta Leonard                         |\n",
            "|Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)      |\n",
            "|Nasser, Mrs. Nicholas (Adele Achem)                    |\n",
            "|Sandstrom, Miss. Marguerite Rut                        |\n",
            "|Bonnell, Miss. Elizabeth                               |\n",
            "|Saundercock, Mr. William Henry                         |\n",
            "|Andersson, Mr. Anders Johan                            |\n",
            "|Vestrom, Miss. Hulda Amanda Adolfina                   |\n",
            "|Hewlett, Mrs. (Mary D Kingcome)                        |\n",
            "|Rice, Master. Eugene                                   |\n",
            "|Williams, Mr. Charles Eugene                           |\n",
            "|Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)|\n",
            "|Masselmani, Mrs. Fatima                                |\n",
            "+-------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F0F9cTZ2Cuz"
      },
      "source": [
        "**Run this code:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kx6OcB-2BBT"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "unionDF= unionDF.withColumn('Title',F.regexp_extract(F.col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
        "unionDF.createOrReplaceTempView('unionDF')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbZeUWS12r59"
      },
      "source": [
        "**Display \"Title\" column and count \"Title\" column:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGkFMtlp1FAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4327723a-5fc4-404e-82a6-ae9b8ff88d0f"
      },
      "source": [
        "spark.sql(\"\"\"SELECT count(*) as count,Title\n",
        "             FROM unionDF\n",
        "             GROUP BY Title\n",
        "             ORDER BY count\n",
        "          \"\"\").show()\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------+\n",
            "|count|   Title|\n",
            "+-----+--------+\n",
            "|    1|     Don|\n",
            "|    1|      Ms|\n",
            "|    1|     Mme|\n",
            "|    2|Jonkheer|\n",
            "|    2|Countess|\n",
            "|    2|    Capt|\n",
            "|    2|     Sir|\n",
            "|    2|    Lady|\n",
            "|    3|   Major|\n",
            "|    4|     Col|\n",
            "|    4|    Mlle|\n",
            "|    9|     Rev|\n",
            "|   11|      Dr|\n",
            "|   56|  Master|\n",
            "|  186|     Mrs|\n",
            "|  257|    Miss|\n",
            "|  786|      Mr|\n",
            "+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLBQDKYu4JOa"
      },
      "source": [
        "**We can see that Dr, Rev, Major, Col, Mlle, Capt, Don, Jonkheer, Countess, Ms, Sir, Lady, and Mme are really rare titles, so create Dictionary and set the value to \"rare\".**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjnx5l5r2Qaf"
      },
      "source": [
        "titles_map={'Dr':\"rare\", \n",
        "           'Rev':\"rare\",\n",
        "           'Major':\"rare\", \n",
        "           'Col':\"rare\", \n",
        "           'Mlle':\"rare\", \n",
        "           'Capt':\"rare\", \n",
        "           'Don':\"rare\", \n",
        "           'Jonkheer':\"rare\", \n",
        "           'Countess':\"rare\", \n",
        "           'Ms':\"rare\", \n",
        "           'Sir':\"rare\", \n",
        "           'Lady':\"rare\",\n",
        "           'Mme':\"rare\",\n",
        "           'Master':'Master',\n",
        "           'Mrs':'Mrs',\n",
        "           'Mr':'Mr',\n",
        "           'Miss':'Miss'}\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wrE95Cv7Oqh"
      },
      "source": [
        "**Run the function:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdDbWuDl7Pf4"
      },
      "source": [
        "@udf(returnType=StringType()) \n",
        "def impute_title(title):\n",
        "    return titles_map[title]# Title_map is your dictionary. please change this name with your dictionary name."
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5EQVIhK7a9R"
      },
      "source": [
        "**Apply the function on \"Title\" column using UDF:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBAiIOn77XFa"
      },
      "source": [
        "# import org.apache.spark.sql.functions.udf package\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "unionDF=unionDF.withColumn(\"Title\", impute_title(F.col(\"Title\")))\n",
        "unionDF.createOrReplaceTempView('unionDF')\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn8ewllf7kiV"
      },
      "source": [
        "**Display \"Title\" from table and group by \"Title\" column:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9sjQb084GU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16ab48c-3bf6-4007-90ee-e35013def8a4"
      },
      "source": [
        "spark.sql(\"\"\"SELECT count(*) as count,Title\n",
        "             FROM unionDF\n",
        "             GROUP BY Title\n",
        "             ORDER BY count\n",
        "          \"\"\").show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+\n",
            "|count| Title|\n",
            "+-----+------+\n",
            "|   44|  rare|\n",
            "|   56|Master|\n",
            "|  186|   Mrs|\n",
            "|  257|  Miss|\n",
            "|  786|    Mr|\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H45QNLj9vJp"
      },
      "source": [
        "## **Preprocessing Age**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwRAhumK-u__"
      },
      "source": [
        "**Based on the \"age\" column mean, you will fill in the missing age values:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXYSVzvl4z63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd2bb12-be1b-4e31-905d-2f4a7f9afaa7"
      },
      "source": [
        "from pyspark.sql.functions import mean as _mean\n",
        "unionDF.select(_mean(col('Age'))).show()\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|          avg(Age)|\n",
            "+------------------+\n",
            "|30.079501879699244|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLPivde8_GI-"
      },
      "source": [
        "**Fill missing with \"age\" mean:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBgW8aFD90PA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e375c7df-7f20-4388-eca9-bbdd9006cf4e"
      },
      "source": [
        "unionDF=unionDF.na.fill(30.079501879699244,subset=['Age'])\n",
        "unionDF.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked| Title|\n",
            "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|              22.0|    1|    0|       A/5 21171|   7.25|    U|       S|    Mr|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|              38.0|    1|    0|        PC 17599|71.2833|    C|       C|   Mrs|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|              26.0|    0|    0|STON/O2. 3101282|  7.925|    U|       S|  Miss|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|              35.0|    1|    0|          113803|   53.1|    C|       S|   Mrs|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|              35.0|    0|    0|          373450|   8.05|    U|       S|    Mr|\n",
            "|          6|       0|     3|    Moran, Mr. James|  male|30.079501879699244|    0|    0|          330877| 8.4583|    U|       Q|    Mr|\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|  male|              54.0|    0|    0|           17463|51.8625|    E|       S|    Mr|\n",
            "|          8|       0|     3|Palsson, Master. ...|  male|               2.0|    3|    1|          349909| 21.075|    U|       S|Master|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female|              27.0|    0|    2|          347742|11.1333|    U|       S|   Mrs|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female|              14.0|    1|    0|          237736|30.0708|    U|       C|   Mrs|\n",
            "|         11|       1|     3|Sandstrom, Miss. ...|female|               4.0|    1|    1|         PP 9549|   16.7|    G|       S|  Miss|\n",
            "|         12|       1|     1|Bonnell, Miss. El...|female|              58.0|    0|    0|          113783|  26.55|    C|       S|  Miss|\n",
            "|         13|       0|     3|Saundercock, Mr. ...|  male|              20.0|    0|    0|       A/5. 2151|   8.05|    U|       S|    Mr|\n",
            "|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5|          347082| 31.275|    U|       S|    Mr|\n",
            "|         15|       0|     3|Vestrom, Miss. Hu...|female|              14.0|    0|    0|          350406| 7.8542|    U|       S|  Miss|\n",
            "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|              55.0|    0|    0|          248706|   16.0|    U|       S|   Mrs|\n",
            "|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1|          382652| 29.125|    U|       Q|Master|\n",
            "|         18|       1|     2|Williams, Mr. Cha...|  male|30.079501879699244|    0|    0|          244373|   13.0|    U|       S|    Mr|\n",
            "|         19|       0|     3|Vander Planke, Mr...|female|              31.0|    1|    0|          345763|   18.0|    U|       S|   Mrs|\n",
            "|         20|       1|     3|Masselmani, Mrs. ...|female|30.079501879699244|    0|    0|            2649|  7.225|    U|       C|   Mrs|\n",
            "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGsnUz-m_P95"
      },
      "source": [
        "## **Preprocessing Embarked**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHbbamcXMSYP"
      },
      "source": [
        "**Select \"Embarked\" column, count them, order by count Desc, and save in grouped_Embarked variable:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-lRu5vc_FW7"
      },
      "source": [
        "grouped_Embarked=spark.sql(\"\"\"SELECT count(*) as count,Embarked\n",
        "             FROM unionDF\n",
        "             GROUP BY Embarked\n",
        "             ORDER BY Embarked Desc\n",
        "          \"\"\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1qf5u2IOQrx"
      },
      "source": [
        "**Show \"groupped_Embarked\" your variable:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSFNDTNg_erb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae404f5b-51f3-4eb3-f387-663ddf83898c"
      },
      "source": [
        "grouped_Embarked.show()\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------+\n",
            "|count|Embarked|\n",
            "+-----+--------+\n",
            "|  965|       S|\n",
            "|  111|       Q|\n",
            "|  253|       C|\n",
            "+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzQWYgKBMrbp"
      },
      "source": [
        "**Get max of groupped_Embarked:** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLYj4F7E_iqb"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8vhoEs8N2w_"
      },
      "source": [
        "**Fill missing values with max 'S' of grouped_Embarked:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdzQCRud_mAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a982b71-a4a0-4399-f317-b8f1e1330ec0"
      },
      "source": [
        "unionDF=unionDF.na.fill(value=\"S\",subset=[\"Embarked\"])\n",
        "unionDF.createOrReplaceTempView('unionDF')\n",
        "grouped_Embarked=spark.sql(\"\"\"SELECT count(*) as count,Embarked\n",
        "             FROM unionDF\n",
        "             GROUP BY Embarked\n",
        "             ORDER BY Embarked Desc\n",
        "          \"\"\")\n",
        "grouped_Embarked.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------+\n",
            "|count|Embarked|\n",
            "+-----+--------+\n",
            "|  965|       S|\n",
            "|  111|       Q|\n",
            "|  253|       C|\n",
            "+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEcdV5Vb_qR_"
      },
      "source": [
        "## **Preprocessing Cabin**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BQzPs7tqhpA"
      },
      "source": [
        "**Replace \"cabin\" column with first char from the string:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b6L5pK0_nQz"
      },
      "source": [
        "first_letter = udf(lambda z: z[0] )\n",
        "unionDF=unionDF.withColumn(\"Cabin\", unionDF.Cabin.substr(0, 1))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H8XshnYj4k2"
      },
      "source": [
        "**Show the result:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJUQwnG1Oj2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e022dcb-b2d0-4fbe-aaf7-66ddd0dc7b22"
      },
      "source": [
        "unionDF.show(5)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Title|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|    U|       S|   Mr|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|    C|       C|  Mrs|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|    U|       S| Miss|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|    C|       S|  Mrs|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|    U|       S|   Mr|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzSDsWsUj9Im"
      },
      "source": [
        "**Create the temporary view:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR7CXTY7_tMJ"
      },
      "source": [
        "unionDF.createOrReplaceTempView('unionDF')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv7lfQFkrLlN"
      },
      "source": [
        "**Select \"Cabin\" column, count \"Cabin\" column, Group by \"Cabin\" column, Order By count DESC**  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0tZG_mvrKXv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e54e4c27-b9c7-4660-a6ef-31a56ee2f772"
      },
      "source": [
        "spark.sql(\"\"\"SELECT count(*) as count,Cabin\n",
        "             FROM unionDF\n",
        "             GROUP BY Cabin\n",
        "             ORDER BY Cabin Desc\n",
        "          \"\"\").show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|count|Cabin|\n",
            "+-----+-----+\n",
            "| 1021|    U|\n",
            "|    1|    T|\n",
            "|    4|    G|\n",
            "|   18|    F|\n",
            "|   51|    E|\n",
            "|   52|    D|\n",
            "|   82|    C|\n",
            "|   77|    B|\n",
            "|   23|    A|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GR6j0LOsB4y"
      },
      "source": [
        "**Fill missing values with \"U\":**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwq5CHEz_up_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e894b092-ec9e-4dd0-8734-06270d6858a6"
      },
      "source": [
        "unionDF=unionDF.na.fill(value=\"U\",subset=[\"Cabin\"])\n",
        "unionDF.createOrReplaceTempView('unionDF')\n",
        "spark.sql(\"\"\"SELECT count(*) as count,Cabin\n",
        "             FROM unionDF\n",
        "             GROUP BY Cabin\n",
        "             ORDER BY Cabin Desc\n",
        "          \"\"\").show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|count|Cabin|\n",
            "+-----+-----+\n",
            "| 1021|    U|\n",
            "|    1|    T|\n",
            "|    4|    G|\n",
            "|   18|    F|\n",
            "|   51|    E|\n",
            "|   52|    D|\n",
            "|   82|    C|\n",
            "|   77|    B|\n",
            "|   23|    A|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b02jouzP7Z2n",
        "outputId": "f8d05d31-be79-4d47-f583-79dec123302c"
      },
      "source": [
        "unionDF.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked| Title|\n",
            "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|              22.0|    1|    0|       A/5 21171|   7.25|    U|       S|    Mr|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|              38.0|    1|    0|        PC 17599|71.2833|    C|       C|   Mrs|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|              26.0|    0|    0|STON/O2. 3101282|  7.925|    U|       S|  Miss|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|              35.0|    1|    0|          113803|   53.1|    C|       S|   Mrs|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|              35.0|    0|    0|          373450|   8.05|    U|       S|    Mr|\n",
            "|          6|       0|     3|    Moran, Mr. James|  male|30.079501879699244|    0|    0|          330877| 8.4583|    U|       Q|    Mr|\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|  male|              54.0|    0|    0|           17463|51.8625|    E|       S|    Mr|\n",
            "|          8|       0|     3|Palsson, Master. ...|  male|               2.0|    3|    1|          349909| 21.075|    U|       S|Master|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female|              27.0|    0|    2|          347742|11.1333|    U|       S|   Mrs|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female|              14.0|    1|    0|          237736|30.0708|    U|       C|   Mrs|\n",
            "|         11|       1|     3|Sandstrom, Miss. ...|female|               4.0|    1|    1|         PP 9549|   16.7|    G|       S|  Miss|\n",
            "|         12|       1|     1|Bonnell, Miss. El...|female|              58.0|    0|    0|          113783|  26.55|    C|       S|  Miss|\n",
            "|         13|       0|     3|Saundercock, Mr. ...|  male|              20.0|    0|    0|       A/5. 2151|   8.05|    U|       S|    Mr|\n",
            "|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5|          347082| 31.275|    U|       S|    Mr|\n",
            "|         15|       0|     3|Vestrom, Miss. Hu...|female|              14.0|    0|    0|          350406| 7.8542|    U|       S|  Miss|\n",
            "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|              55.0|    0|    0|          248706|   16.0|    U|       S|   Mrs|\n",
            "|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1|          382652| 29.125|    U|       Q|Master|\n",
            "|         18|       1|     2|Williams, Mr. Cha...|  male|30.079501879699244|    0|    0|          244373|   13.0|    U|       S|    Mr|\n",
            "|         19|       0|     3|Vander Planke, Mr...|female|              31.0|    1|    0|          345763|   18.0|    U|       S|   Mrs|\n",
            "|         20|       1|     3|Masselmani, Mrs. ...|female|30.079501879699244|    0|    0|            2649|  7.225|    U|       C|   Mrs|\n",
            "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRnhA_5-0Hi4"
      },
      "source": [
        "**StringIndexer: A label indexer that maps a string column of labels to an ML column of label indices. If the input column is numeric, we cast it to string and index the string values. The indices are in [0, numLabels). By default, this is ordered by label frequencies so the most frequent label gets index 0. The ordering behavior is controlled by setting stringOrderType. Its default value is ‘frequencyDesc’.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RIKlOX71GQ-"
      },
      "source": [
        "**StringIndexer(inputCol=None, outputCol=None)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odhuI2EHKuCm"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler,OneHotEncoder\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "categoricalCols = [field for (field, dataType) in unionDF.dtypes\n",
        "                   if dataType == \"string\"]\n",
        "\n",
        "indexOutputCols = [x + \"_Index\" for x in categoricalCols]\n",
        "\n",
        "\n",
        "stringIndexer = StringIndexer(inputCols=categoricalCols,\n",
        "                             outputCols=indexOutputCols,\n",
        "                             handleInvalid='skip')"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DECL9yCK3JZ"
      },
      "source": [
        "**OneHotEncoder(inputCols=None, outputCols=None)**\n",
        "\n",
        "A one-hot encoder that maps a column of category indices to a column of binary vectors, with at most a single one-value per row that indicates the input category index. For example with 5 categories, an input value of 2.0 would map to an output vector of [0.0, 0.0, 1.0, 0.0]. The last category is not included by default (configurable via dropLast), because it makes the vector entries sum up to one, and hence linearly dependent. So an input value of 4.0 maps to [0.0, 0.0, 0.0, 0.0]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiAjDEy1LBhz"
      },
      "source": [
        "\n",
        "oheOutputCols = [x + \"_OHE\" for x in categoricalCols]\n",
        "\n",
        "oheEncoder = OneHotEncoder(inputCols=indexOutputCols,\n",
        "                          outputCols=oheOutputCols)\n",
        "\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FsiLsd9452v"
      },
      "source": [
        "**VectorAssembler: VectorAssembler(*, inputCols=None, outputCol=None). A feature transformer that merges multiple columns into a vector column.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuytKk0hLE6p"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "numericCols = [field for (field,dataType) in unionDF.dtypes\n",
        "              if ((dataType=='double')& (field!='Survived'))]\n",
        "\n",
        "assemblerInputs = oheOutputCols + numericCols\n",
        "\n",
        "vecAssembler = VectorAssembler(inputCols=assemblerInputs,outputCol='features')"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU8DeZfh7JIo"
      },
      "source": [
        "**Use randomSplit function and split data to x_train, and X_test with 80% and 20% Consecutive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C11xf1iAzKp"
      },
      "source": [
        "X_train, X_test = unionDF.randomSplit([0.8, 0.2],seed = 10)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0c_Hf_b0R12"
      },
      "source": [
        "**Pipeline: ML Pipelines provide a uniform set of high-level APIs built on top of DataFrames that help users create and tune practical machine learning pipelines.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJQvmFai72O7"
      },
      "source": [
        "**Build RandomForestClassifier model and use pipeline to fit and transform then display \"prediction, Survived, features\" columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnpmZqlTLPGq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a3e437a-d396-4fee-a880-d92c27bca653"
      },
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'Survived')\n",
        "pipeline = Pipeline(stages=[stringIndexer,oheEncoder,vecAssembler,rf])\n",
        "\n",
        "predictions = pipeline.fit(X_train).transform(X_test)\n",
        "\n",
        "predictions.select(\"prediction\", \"Survived\", \"features\").show()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+--------------------+\n",
            "|prediction|Survived|            features|\n",
            "+----------+--------+--------------------+\n",
            "|       0.0|       0|(1405,[607,779,12...|\n",
            "|       0.0|       0|(1405,[576,779,13...|\n",
            "|       1.0|       1|(1405,[524,1356,1...|\n",
            "|       1.0|       1|(1405,[512,893,13...|\n",
            "|       0.0|       0|(1405,[542,779,11...|\n",
            "|       0.0|       1|(1405,[279,779,13...|\n",
            "|       0.0|       0|(1405,[701,779,13...|\n",
            "|       0.0|       0|(1405,[634,1191,1...|\n",
            "|       0.0|       1|(1405,[667,835,13...|\n",
            "|       0.0|       1|(1405,[275,779,10...|\n",
            "|       1.0|       1|(1405,[504,864,13...|\n",
            "|       0.0|       1|(1405,[675,1385,1...|\n",
            "|       0.0|       0|(1405,[441,779,13...|\n",
            "|       0.0|       0|(1405,[376,1182,1...|\n",
            "|       0.0|       0|(1405,[374,779,10...|\n",
            "|       0.0|       0|(1405,[676,779,12...|\n",
            "|       1.0|       1|(1405,[414,862,13...|\n",
            "|       0.0|       0|(1405,[428,779,85...|\n",
            "|       0.0|       0|(1405,[623,779,12...|\n",
            "|       0.0|       0|(1405,[699,779,11...|\n",
            "+----------+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSXEI8-r8bKY"
      },
      "source": [
        "**Use MulticlassClassificationEvaluator and set the \"labelCol\" to \"Survived\",  \"predictionCol\" to \"prediction\", \"metricName\" to \"accuracy\"** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl0UAKCaBDO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7829f72-7c30-4b2f-c6d2-9b96cc14d255"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "print(\"Accuracy : \" + str(evaluator.evaluate(predictions)))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.821917808219178\n"
          ]
        }
      ]
    }
  ]
}